
Natural Language Processing
===========================

**Important note**: This is a website hosting NLP-related teaching
materials. If you are a student at NYU taking the course, please go to
the official course website for up-to-date information.

Accessibility
-------------

We try to make all of the course material accessible. If you need
additional accomadation, please send us an email.

Course information
------------------

How can we teach machines to understand language so that they can answer
our queries, extract information from textual data, or even have a
conversation with us? The primary goal of this course is to provide
students with the principles and tools needed to solve a variety of NLP
problems. We will focus on data-driven methods, including
classification, sequence labeling, structured prediction, unsupervised
learning, and deep learning. Specific applications include text
classification, constituent parsing, semantic parsing, and generation.

Prerequisites
~~~~~~~~~~~~~

Students are expected to have solid mathematic background and
programming skills.

-  Probability, statistics, linear algebra (DS-GA.1002, MATH-UA.140,
   MATH-UA.235)
-  Algorithms and data structure (CSCI-UA.102)
-  Basic knowlege in machine learning (DS-GA.1003, CSCI-UA.0473) will be
   helpful

Resources
~~~~~~~~~

**Textbook:** There is no required textbook. Course notes/slides should
be sufficient. Some lectures will be based on the following books
(available freely online):

-  `Dan Jurafsky and James H. Martin. Speech and Language
   Processing. <https://web.stanford.edu/~jurafsky/slp3/>`__ A classic
   textbook covering both traditional and modern approaches to NLP.
-  `Jacob Eisenstein. Introduction to Natural Language
   Processing. <https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf>`__
   A comprehensive reference with additional coverage on relevant topics
   in linguistics and slightly more advanced topics in machine learning.
-  `Yoav Goldberg. Neural Network Methods for Natural Language
   Processing. <https://u.cs.biu.ac.il/~yogo/nnlp.pdf>`__ Covers neural
   network models for NLP.
-  `Aston Zhang, Zack C. Lipton, Mu Li, and Alex J. Smola. Dive into
   Deep Learning. <https://d2l.ai/index.html>`__ Covers many topics in
   neural networks and features numerous hands-on examples. We will use
   some examples from this book.

In the lecture notes, we will use JM, E, G, D2L to refer to the above
books respectively.

**Background**: Here are some useful materials if you want to review the
background knowledge.

-  Probability and optimization in the appendix of Eisensteinâ€™s book.
-  `Notes <https://cims.nyu.edu/~cfgranda/pages/DSGA1002_fall15/notes.html>`__
   from DS-GA.1002.
-  Machine learning material from
   `DS-GA.1003 <https://davidrosenberg.github.io/ml2019/#home>`__.

.. toctree::
   :maxdepth: 2
   :hidden:

   schedule
   coursework
   notes/index
